{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hand-sign recognizer\n",
    "Here we build a convolutional neural-network for recognizing hand-signs.\n",
    "\n",
    "> Inspired by: [Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available.\n",
      "Setting torch.cuda.DoubleTensor as default dtype...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import h5py\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available(): # TODO: remove the false\n",
    "    print(\"Cuda available.\")\n",
    "    tensor_type = 'torch.cuda.DoubleTensor'\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "else:\n",
    "    print(\"Cuda not found.\")\n",
    "    tensor_type = 'torch.DoubleTensor'\n",
    "\n",
    "print(f\"Setting {tensor_type} as default dtype...\")\n",
    "torch.set_default_tensor_type(tensor_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training-examples: 1080\n",
      "# of test-examples: 120\n",
      "image-dimensions: (64, 64, 3)\n",
      "class-labels: [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, class_labels = None, None, None, None, None\n",
    "with h5py.File(\"../data/test-hand-signs.h5\", \"r\") as f:\n",
    "    test_x = np.array(f[\"test_set_x\"])\n",
    "    test_y = np.array(f[\"test_set_y\"])\n",
    "\n",
    "with h5py.File(\"../data/train-hand-signs.h5\", \"r\") as f:\n",
    "    train_x = np.array(f[\"train_set_x\"])\n",
    "    train_y = np.array(f[\"train_set_y\"])\n",
    "    class_labels = np.array(f[\"list_classes\"])\n",
    "\n",
    "print(f\"# of training-examples: {train_x.shape[0]}\")\n",
    "print(f\"# of test-examples: {test_x.shape[0]}\")\n",
    "print(f\"image-dimensions: {test_x.shape[1:]}\")\n",
    "print(f\"class-labels: {class_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #pre-processing\n",
    "We will perform mean and variance normalization of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-set X: (1080, 64, 64, 3), Y: (6, 1080)\n",
      "Test-set X: (120, 64, 64, 3), Y: (6, 120)\n"
     ]
    }
   ],
   "source": [
    "train_mean = np.mean(a=train_x, axis=0)\n",
    "train_std = np.std(a=train_x, axis=0)\n",
    "\n",
    "# train-set normalization\n",
    "train_X = (train_x - train_mean) / train_std\n",
    "train_Y = np.eye(len(class_labels))[:, train_y].copy()\n",
    "\n",
    "# test-set normalization\n",
    "test_X = (test_x - train_mean) / train_std\n",
    "test_Y = np.eye(len(class_labels))[:, test_y].copy()\n",
    "\n",
    "print(f\"Train-set X: {train_X.shape}, Y: {train_Y.shape}\")\n",
    "print(f\"Test-set X: {test_X.shape}, Y: {test_Y.shape}\")\n",
    "\n",
    "cu_train_X = torch.tensor(train_X)\n",
    "cu_train_Y = torch.tensor(train_Y)\n",
    "cu_test_X = torch.tensor(test_X)\n",
    "cu_test_Y = torch.tensor(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # architecture\n",
    "We will use a 3-layer CNN, as defined below:\n",
    "\n",
    "<center>\n",
    "\n",
    "| #-layer | layer-type      | component        | properties                           |         |\n",
    "|---------|-----------------|------------------|--------------------------------------|---------|\n",
    "| 1       | 2d-convolution  | kernel           | $(h^{[1]}_k, w^{[1]}_k)$             | $(4,4)$ |\n",
    "|         |                 | #-kernels        | $c^{[1]}$                            | 8       |\n",
    "|         |                 | convolve-padding | $(h^{[1]}_p, w^{[1]}_p)$             | <same>  |\n",
    "|         |                 | convolve-stride  | $(h^{[1]}_s, w^{[1]}_s)$             | $(1,1)$ |\n",
    "|         |                 | pooling          | max-pooling                          |         |\n",
    "|         |                 | pooling-filter   | $(h^{[1]}_l, w^{[1]}_l)$             | $(8,8)$ |\n",
    "|         |                 | pooling-padding  | $({}^{l}h^{[1]}_p, {}^{l}w^{[1]}_p)$ |`<same>` |\n",
    "|         |                 | pooling-stride   | $({}^{l}h^{[1]}_s, {}^{l}w^{[1]}_s)$ | $(8,8)$ |\n",
    "|         |                 | activation       | ReLU                                 |         |\n",
    "| 2       | 2d-convolution  | kernel           | $(h^{[2]}_k, w^{[2]}_k)$             | $(2,2)$ |\n",
    "|         |                 | #-kernels        | $c^{[2]}$                            | 16      |\n",
    "|         |                 | convolve-padding | $(h^{[2]}_p, w^{[2]}_p)$             |`<same>` |\n",
    "|         |                 | convolve-stride  | $(h^{[2]}_s, w^{[2]}_s)$             | $(1,1)$ |\n",
    "|         |                 | pooling          | max-pooling                          |         |\n",
    "|         |                 | pooling-filter   | $(h^{[2]}_l, w^{[2]}_l)$             | $(4,4)$ |\n",
    "|         |                 | pooling-padding  | $({}^{l}h^{[2]}_p, {}^{l}w^{[2]}_p)$ |`<same>` |\n",
    "|         |                 | pooling-stride   | $({}^{l}h^{[2]}_s, {}^{l}w^{[2]}_s)$ | $(4,4)$ |\n",
    "|         |                 | activation       | ReLU                                 |         |\n",
    "| 3       | fully-connected | #-neurons        | $n^{[3]}$                            | $6$     |\n",
    "|         |                 | activation       | softmax                              |         |\n",
    "\n",
    "</center>\n",
    "\n",
    "Also, the number of channels in the input, i.e. $c^{[0]} = 3$.\n",
    "\n",
    "* Given the stride and kernel, `<same>` padding refers to the padding regime wherein the output immediately after the convolution is of the same size as that of the input, i.e.\n",
    "$$\n",
    "h^{[l]}_z = \\left\\lfloor\\frac{h^{[l]}_a + 2h^{[l]}_p - h^{[l]}_k}{h^{[l]}_s} + 1\\right\\rfloor = h^{[l]}_a;\\qquad w^{[l]}_z = \\left\\lfloor\\frac{w^{[l]}_a + 2w^{[l]}_p - w^{[l]}_k}{w^{[l]}_s} + 1\\right\\rfloor = w^{[l]}_a\n",
    "$$\n",
    "\n",
    "## # forward-propagation\n",
    "> **Note**: for the forward-propagation equations, read [Section-2, Back-propagation: Conv2D](./back-propagation_Conv2D.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve(A: torch.Tensor, K: torch.Tensor, model: dict, layer: int):\n",
    "    pass\n",
    "\n",
    "def relu(Z: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.maximum(Z, torch.tensor(0))\n",
    "\n",
    "sftmx = torch.nn.Softmax(dim=0)\n",
    "def softmax(Z: torch.Tensor) -> torch.Tensor:\n",
    "    return sftmx(Z)\n",
    "\n",
    "def linear(W: torch.Tensor, A: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.matmul(W.T, A) + b\n",
    "\n",
    "def activation(Zl: torch.Tensor, func_name: str) -> torch.Tensor:\n",
    "    if func_name == 'relu':\n",
    "        return relu(Zl)\n",
    "    elif func_name == 'softmax':\n",
    "        return softmax(Zl)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown activation-function: {func_name}\")\n",
    "\n",
    "def forward_propogate(X: torch.Tensor, model: dict) -> tuple:\n",
    "    L: int = model[\"L\"]\n",
    "    \n",
    "    cache = {'m': X.shape[1], 'c-l0': (X, None, None, None)}\n",
    "\n",
    "    Al_1 = X\n",
    "    Al = None\n",
    "    for l in range(L):\n",
    "        Wl = model['W-l' + str(l + 1)]\n",
    "        bl = model['b-l' + str(l + 1)]\n",
    "        Zl = linear(Wl, Al_1, bl)\n",
    "        Al = activation(Zl, model['g-l' + str(l + 1)])\n",
    "        cache['c-l' + str(l + 1)] = (Al.clone(), Wl.clone(), bl.clone(), Zl.clone())\n",
    "        \n",
    "        Al_1 = Al\n",
    "    \n",
    "    return Al, cache\n",
    "\n",
    "def softmax_cost(Al: torch.Tensor, Y: torch.Tensor, **kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Assumes Y and Al to be (nl,m) dimensional vectors\n",
    "    \"\"\"\n",
    "    assert Al.shape == Y.shape\n",
    "\n",
    "    return torch.multiply(-Y, torch.log(Al)).sum() / Al.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([64, 64, 3]) stride: (192, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "s = cu_train_X[0]\n",
    "print(f\"shape: {s.shape} stride: {s.stride()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.stride: (20, 4) type: int32\n",
      "shape: torch.Size([3, 5]) stride: (5, 1)\n",
      "x: tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.,  9., 10.],\n",
      "        [11., 12., 13., 14., 15.]])\n",
      "shape: torch.Size([2, 3]) stride: (3, 1)\n",
      "y: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(start=1,step=1,stop=16).reshape((3,5))\n",
    "print(f\"np.stride: {x.strides} type: {x.dtype}\")\n",
    "x = torch.Tensor(x)\n",
    "print(f\"shape: {x.shape} stride: {x.stride()}\")\n",
    "print(f\"x: {x}\")\n",
    "\n",
    "y = np.arange(start=1,step=1,stop=7).reshape((2,3))\n",
    "y = torch.Tensor(y)\n",
    "print(f\"shape: {y.shape} stride: {y.stride()}\")\n",
    "print(f\"y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "x.as_strided = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "80fe1bb2d351c7da6118ff9c1a62c9784868a6763a6756e3322751dc6fcdcdcc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
